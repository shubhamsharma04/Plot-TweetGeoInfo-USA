{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install all the dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "install.packages(\"twitteR\",repos=\"http://cran.us.r-project.org\")\n",
    "install.packages(\"ggmap\",repos=\"http://cran.us.r-project.org\")\n",
    "install.packages(\"hash\",repos=\"http://cran.us.r-project.org\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Because of the ggmap library, suppress the warning messages\n",
    "options(warn=-1)\n",
    "sink(\"log.out\")\n",
    "library(twitteR)\n",
    "library(ggmap)\n",
    "library(ggplot2)\n",
    "library(hash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Using direct authentication\"\n"
     ]
    }
   ],
   "source": [
    "setup_twitter_oauth(\"\",\"\",\"\",\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute the cell below to download tweets related to a topic and convert them into data frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Downlaod tweets\n",
    " topic <- '#nfl'\n",
    " tweets <- searchTwitter(topic, n=1000)\n",
    "#Covert into data frames\n",
    " tweets_df <- twListToDF(tweets)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group screen names becuase location is to be determined via screen name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# UserName to Count map\n",
    "# I asked a question related to the code below @ https://stackoverflow.com/questions/42238057/has-key-method-in-hash-package-of-r-not-storing-string-key-properly\n",
    "# Please have a look \n",
    "user_count_map <- hash()\n",
    " i=1\n",
    " num_tweets <- nrow(tweets_df)\n",
    " while(i<= num_tweets){\n",
    " screen_name <- tweets_df[i,]$screenName\n",
    " if(has.key(screen_name,user_count_map)==TRUE){\n",
    "    count <- user_count_map[[screen_name]]\n",
    "    user_count_map[[screen_name]] <- (count +1)\n",
    "} else {\n",
    "   user_count_map[[screen_name]] <- 1\n",
    "}\n",
    "i = i+1\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get All Locations and get location to count mapping. This way the number of unique locations would reduce and hence lesser number of API calls would be required "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get All Locations and get location to count mapping\n",
    " all_users <- lookupUsers(keys(user_count_map))\n",
    " location_count_map <- hash()\n",
    " for(u in all_users){\n",
    "location <- u$location\n",
    "screenName <- u$screenName\n",
    " if(!is.null(location) && location!=\"\"){\n",
    "if((has.key(location,location_count_map))==TRUE){\n",
    "    location_count_map[[location]] <- location_count_map[[location]] + user_count_map[[screenName]]\n",
    "} else {\n",
    " location_count_map[[location]] <- user_count_map[[screenName]]\n",
    "} \n",
    "}\n",
    "i=i+1\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get all the geocodes to count mapping. Only take those geocodes which falls in US. To check if the location is in US, search for the reverse geocode check if the address ends with \"USA\". This step may take a long time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get all the geocodes to count mapping. Only take those geocodes which falls in US\n",
    "# DIscard all locations which donot fall within US boundaries\n",
    "reg <- \"USA$\"\n",
    "allLocs <- keys(location_count_map)\n",
    "lat_lon_count_map <- hash()\n",
    "for(loc in allLocs){\n",
    "    code <- geocode(loc)\n",
    "    if(!is.na(code$lon)){\n",
    "        rev_loc <- c(code$lon,code$lat)\n",
    "        rev <- revgeocode(rev_loc)\n",
    "        if(any(grep(reg,rev))){\n",
    "            str <- c(code$lon,\",\",code$lat)\n",
    "            str_2 <- paste(str,collapse='')\n",
    "            if(has.key(str_2,lat_lon_count_map)){\n",
    "                lat_lon_count_map[[str_2]] <- lat_lon_count_map[[str_2]] + location_count_map[[loc]]\n",
    "            } else {\n",
    "                lat_lon_count_map[[str_2]] <- location_count_map[[loc]]\n",
    "            }\n",
    "            #print(\"Correct\")\n",
    "        } else {\n",
    "            #print(\"Correct but irrelevant\")\n",
    "            }\n",
    "    } else {\n",
    "        #print(\"Google couldn't give Lat/Long for this address\")\n",
    "    }\n",
    "}\n",
    "\n",
    "locationKeys = keys(lat_lon_count_map)\n",
    "#values <- values(lat_lon_count_map)\n",
    "#values\n",
    "write(\"\",file=topic,append=FALSE,sep='')\n",
    "for(location in locationKeys){\n",
    "    count <- lat_lon_count_map[[location]]\n",
    "    write(location,file=topic,append=TRUE,sep='\\n')\n",
    "    write(count,file=topic,append=TRUE,sep='\\n')\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you already have a file in specific format, skip the above steps and read the file. \n",
    "\n",
    "**** Important ****\n",
    "If you want to plot fresh data, please use the file name as 'coord_values' ie replace topic with 'coord_values' (including the single quotes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read Co-ordinates from file\n",
    "coord_data <- read.table(topic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To give more significance to locations from where more tweets were obtained, get the maximum count among all the locations and set the size and alpha of "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "-104.990251,39.7392358"
      ],
      "text/latex": [
       "-104.990251,39.7392358"
      ],
      "text/markdown": [
       "-104.990251,39.7392358"
      ],
      "text/plain": [
       "[1] -104.990251,39.7392358\n",
       "132 Levels: -101.8551665,33.5778631 ... 9"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "length <- nrow(coord_data)\n",
    "# get max count\n",
    "max <- as.numeric(0)\n",
    "i=2\n",
    "#as.numeric(as.character(coord_data[[1]][4]))\n",
    "while(i<=length){\n",
    "    count <- as.numeric(as.character(coord_data[[1]][i]))\n",
    "    #print(count)\n",
    "    if(count>max){\n",
    "        max<-count\n",
    "    }\n",
    "    i=i+2\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot\n",
    "i = 1\n",
    "usMap <- get_map(zoom=4)\n",
    "usMap <- ggmap(usMap)\n",
    "print(max)\n",
    "while(i<=length-1){\n",
    "    coord_loc <- coord_data[[1]][i]\n",
    "    count <- as.numeric(as.character(coord_data[[1]][i+1]))\n",
    "    #print(count)\n",
    "    a <- count/max\n",
    "    if(a>.5){\n",
    "        a=.5\n",
    "    }\n",
    "    s<- (count/max)*2\n",
    "    inp <- as.character(coord_loc)\n",
    "    inp <- strsplit(inp,',')\n",
    "    gd <- data.frame(lat=c(as.numeric(inp[[1]][2])),lon=c(as.numeric(inp[[1]][1])))\n",
    "    usMap <- usMap + geom_point(data=gd,aes(x=lon, y=lat),size=s+1,alpha=.5 + a) \n",
    "    i=i+2\n",
    "    \n",
    "}\n",
    "ggplot_build(usMap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.3.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
